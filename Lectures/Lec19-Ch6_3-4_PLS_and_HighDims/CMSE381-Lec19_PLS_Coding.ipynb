{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dfd68f5",
   "metadata": {},
   "source": [
    "# Lecture 19 - Lab: PLS\n",
    "## CMSE 381 - Fall 2022\n",
    "## Oct 28, 2022\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea3a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everyone's favorite standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# ML imports we've used previously\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450cfbaa",
   "metadata": {},
   "source": [
    "# PLS on Hitters Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f9a257",
   "metadata": {},
   "source": [
    "# Loading in the data\n",
    "\n",
    "Ok, here we go, let's play with a baseball data set again. Note this cleanup is all the same as the last lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceeb83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Hitters.csv').dropna().drop('Player', axis = 1)\n",
    "df.info()\n",
    "dummies = pd.get_dummies(df[['League', 'Division', 'NewLeague']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4672d6f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y = df.Salary\n",
    "\n",
    "# Drop the column with the independent variable (Salary), and columns for which we created dummy variables\n",
    "X_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis = 1).astype('float64')\n",
    "\n",
    "# Define the feature set X.\n",
    "X = pd.concat([X_, dummies[['League_N', 'Division_W', 'NewLeague_N']]], axis = 1)\n",
    "\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a123c81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And here we have the normalized data.\n",
    "X_normalized = X/X.std()\n",
    "X_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533b855d",
   "metadata": {},
   "source": [
    "# Principal Least Squares (PLS)\n",
    "\n",
    "The command do do PLS in `Scikit-learn` is  `PLSRegression`. Below is a quick code that runs PLS on our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676632dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685f4456",
   "metadata": {},
   "outputs": [],
   "source": [
    "pls = PLSRegression(n_components=3)\n",
    "pls.fit(X_normalized,y)\n",
    "yhat = pls.predict(X_normalized)\n",
    "mean_squared_error(y,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ea5c2e",
   "metadata": {},
   "source": [
    "But like last time, we can also use the `cross_val_score` function to get the CV score easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c70dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pls = PLSRegression(n_components=3)\n",
    "scores = cross_val_score(pls, X_normalized, y, cv=10, scoring='neg_mean_squared_error')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23da5ab",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>**  Like last time, your job is to test a PLS model for an increasing number of components used. I recommend using the `cross_val_score` with `scoring='neg_mean_squared_error'`. What number of components would you use? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a790749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(X_normalized)\n",
    "mse = []\n",
    "\n",
    "# Calculate MSE using CV for an increasing number of components, \n",
    "# adding one component at a time.\n",
    "for i in np.arange(1, 20): # i is the number of components to use each time\n",
    "    # ====\n",
    "    score = 0 # Your code to figure out the score each time goes in here. \n",
    "    # ====\n",
    "\n",
    "    mse.append(score)\n",
    "    \n",
    "# Plot results    \n",
    "plt.plot(mse, '-v')\n",
    "plt.xlabel('Number of  components in regression')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Predicting Salary')\n",
    "plt.xlim(xmin=-1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0619ddb1",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>**  Below is my code from doing the PCR version on this data set from last class. Draw the two plots overlaid: The test MSE from doing PLS and that form doing PCR.  What do you notice? Which model would you pick with which number of components and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9dd4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "X_PCs = pca.fit_transform(X_normalized)\n",
    "\n",
    "# 10-fold CV, with shuffle included. \n",
    "# You can just put in `cv=10` below, but this doesn't shuffle the data\n",
    "n = len(X_normalized)\n",
    "kf_10 = KFold( n_splits=10, shuffle=True, random_state=48864)\n",
    "\n",
    "regr = LinearRegression()\n",
    "msePCA = []\n",
    "\n",
    "# Calculate MSE using CV for the 19 principal components, adding one component at the time.\n",
    "for i in np.arange(1, 20):\n",
    "    score = -1*cross_val_score(regr, X_PCs[:,:i], y.ravel(), cv=kf_10, scoring='neg_mean_squared_error').mean()\n",
    "    msePCA.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac1b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your plot code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f79113",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "-----\n",
    "### Congratulations, we're done!\n",
    "Written by Dr. Liz Munch, Michigan State University\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribution-NonCommercial 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcfed3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
