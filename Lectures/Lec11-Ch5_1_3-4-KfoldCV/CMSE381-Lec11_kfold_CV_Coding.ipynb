{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dfd68f5",
   "metadata": {},
   "source": [
    "# Lab: K-Fold CV \n",
    "## CMSE 381 - Fall 2022\n",
    "## Oct 5,  2022. Lecture 11\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea3a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everyone's favorite standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c97fb9a",
   "metadata": {},
   "source": [
    "# 1. Roll your own $k$-fold\n",
    "\n",
    "Ok, let's try to get a handle on what this $k$-fold CV is doing with our data. To do that, we're going to build our own $k$-fold splitter before we use the provided tools in `scikitlearn`. Of course, this is not going to be optimized at all, the goal is just to figure out how the innards are working. \n",
    "\n",
    "&#9989; **<font color=red>Do this:</font>** Below is the skeleton of code that will return the $k$-fold train/test splits. Update the code where noted to make it work. \n",
    "\n",
    "How do you check that your code is doing what you want? \n",
    "- Make sure you end up with $k$ splits \n",
    "- Make sure that each of the testing splits has $n/k$ data points\n",
    "- Make sure that the rest of the data points end up in the training set. \n",
    "- A good check is to see that you have all $n$ data points between the training and testing set every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cf303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mykfold(n,k):\n",
    "    # Input: integers n and k.\n",
    "    #        This version is only going to allow us to work with  \n",
    "    #        a $k$ that is actually divisible by $n$ \n",
    "    # Output: a list of the train/test splits to be used.\n",
    "    \n",
    "    # This command is just going to make a warning so that if you pass in \n",
    "    # n and k not divisble, the code will kick you out.     \n",
    "    assert (n % k == 0), \"k doesn't divide n, this code can't handle it\"\n",
    "    \n",
    "    # Make an array of the indices:\n",
    "    all_my_indices = np.array(range(n))\n",
    "    \n",
    "    \n",
    "    # First, shuffle your array to make sure we're working with randomized order.\n",
    "    # ----your code here to shuffle----# \n",
    "    \n",
    "    \n",
    "    # Write an equation that will figure out the length of each fold below\n",
    "    length_of_fold = np.nan #<----- fix this\n",
    "    \n",
    "    \n",
    "    # Now we're going to keep a list of all your splits. Modify the code below so that \n",
    "    # you can keep track of the training and testing splits.\n",
    "    AllSplits = []\n",
    "    for i in range(k):\n",
    "        \n",
    "        test_set = [] #<------ fix this\n",
    "        training_set = [] #<------ fix this, too\n",
    "        AllSplits.append({'train': training_set, 'test':test_set})\n",
    "    \n",
    "    return AllSplits\n",
    " \n",
    "n = 30\n",
    "k = 5\n",
    "mykfold(n,k)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74be4c2",
   "metadata": {},
   "source": [
    "Now we are going to fix the code above to allow for $n$ not divisible by $k$. We want to take all the leftover data points from dividing the folds evenly and just add them to the first folds. Below is one way to figure out how long each fold should be in this more general case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103315ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 33\n",
    "k = 5\n",
    "\n",
    "length_of_each_fold = [n//k for i in range(k)]\n",
    "\n",
    "for i in range(n % k):\n",
    "    length_of_each_fold[i]+=1\n",
    "    \n",
    "print(length_of_each_fold)\n",
    "print(np.sum(length_of_each_fold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e60960",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** Copy your `mykfold` function down here.  Modify it so that it can accept $n$ and $k$ that aren't divisible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a8879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here #\n",
    "\n",
    "n = 33\n",
    "k = 5\n",
    "mykfold(n,k)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fd52f9",
   "metadata": {},
   "source": [
    "# 2. Letting scikitlearn do the work for us. \n",
    "\n",
    "Ok, now that we understand the innards, we can let `scikitlearn` do this for us. Let's get our toy data set back to mess with this.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e321f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed so everyone has the same numbers\n",
    "np.random.seed(42)\n",
    "\n",
    "def f(t, m = -3, b = 2):\n",
    "    return m*t+b\n",
    "\n",
    "n = 300\n",
    "X_toy = np.random.uniform(0,5,n)\n",
    "y_toy = f(X_toy) + np.random.normal(0,2,n)\n",
    "\n",
    "plt.scatter(X_toy,y_toy)\n",
    "plt.plot(X_toy,f(X_toy),c = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695c4c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "# Notice that like the leave one out version, trying to print kf still doesn't \n",
    "# give us much that's useful\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a6dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X_toy):\n",
    "    print(\"TRAIN:\", train_index, \"\\nTEST:\", test_index, '\\n')\n",
    "    X_train, X_test = X_toy[train_index], X_toy[test_index]\n",
    "    y_train, y_test = y_toy[train_index], y_toy[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a260d25",
   "metadata": {},
   "source": [
    "There is a BIG PROBLEM with this code.  We haven't done something!!! Something important!!!\n",
    "\n",
    "&#9989; **<font color=red>Q:</font>** What didn't we do? This is an easy fix, checkout the [documentation for `KFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html), then modify the code below to fix the problem. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9cac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix this code! \n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "for train_index, test_index in kf.split(X_toy):\n",
    "    print(\"TRAIN:\", train_index, \"\\nTEST:\", test_index, '\\n')\n",
    "    X_train, X_test = X_toy[train_index], X_toy[test_index]\n",
    "    y_train, y_test = y_toy[train_index], y_toy[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8a9941",
   "metadata": {},
   "source": [
    "Now that we have our train/test split generator set up, let's take a look at the result. Note that this is just going to color by the last split generated in that for loop up above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f269e617",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train,y_train, marker = '+', label = \"Training\")\n",
    "plt.scatter(X_test,y_test, marker = '*', label = \"Testing\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9500f236",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** Below is my code from last class to train our linear regression model, again just using that last train/test split. Fix this so that it uses every k-fold train/test split ($k=5$) and returns the average of the MSEs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f062b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train.reshape(-1,1),y_train)\n",
    "y_hat = model.predict(X_test.reshape(-1,1))\n",
    "\n",
    "mean_squared_error(y_hat,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f342e47",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** What happens if you set `n_splits = n`? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca51e030",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430024cc",
   "metadata": {},
   "source": [
    "\n",
    "![Stop Icon](https://upload.wikimedia.org/wikipedia/commons/thumb/1/1e/Vienna_Convention_road_sign_B2a.svg/180px-Vienna_Convention_road_sign_B2a.svg.png)\n",
    "\n",
    "Great, you got to here! Hang out for a bit, there's more lecture before we go on to the next portion. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006fbd25",
   "metadata": {},
   "source": [
    "# 2. Setting this up on a slightly more complicated data set. \n",
    "\n",
    "Ok, let's see how this is used for determining parameters. Below, we're going to generate a data set that is clearly non-linear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa8b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed so everyone has the same numbers\n",
    "np.random.seed(42)\n",
    "\n",
    "def f(t, m1 = -7,m2 = 5, m3 = -.8, b = 6):\n",
    "    return m3 * t**3 + m2*t**2 + m1*t+b\n",
    "\n",
    "n = 300\n",
    "X_toy = np.random.uniform(0,5,n)\n",
    "y_toy = f(X_toy) + np.random.normal(0,2,n)\n",
    "\n",
    "plt.scatter(X_toy,y_toy)\n",
    "\n",
    "# Doing this so the plot isn't ugly\n",
    "X_plot = X_toy.copy()\n",
    "X_plot.sort()\n",
    "plt.plot(X_plot,f(X_plot),c = 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557bb101",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** Using $k$-fold cross validation for $k=5$, set up code to approximate the test error for each of the polynomial models below. \n",
    "- $y = \\beta_0 + \\beta_1 X$\n",
    "- $y = \\beta_0 + \\beta_1 X + \\beta_2 X^2$\n",
    "- $y = \\beta_0 + \\beta_1 X+ \\beta_2 X^2+ \\beta_3 X^3$\n",
    "- $y = \\beta_0 + \\beta_1 X+ \\beta_2 X^2+ \\beta_3 X^3+ \\beta_4 X^4$\n",
    "- $y = \\beta_0 + \\beta_1 X+ \\beta_2 X^2+ \\beta_3 X^3+ \\beta_4 X^4+ \\beta_5 X^5$\n",
    "- $y = \\beta_0 + \\beta_1 X+ \\beta_2 X^2+ \\beta_3 X^3+ \\beta_4 X^4+ \\beta_5 X^5+ \\beta_6 X^6$\n",
    "\n",
    "Then plot your resulting test errors for each to deterimine best choice of polynomial for this data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58897f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9a5ce5",
   "metadata": {},
   "source": [
    "If you still have some time, try to see if you can figure out the test errors for everything through a degree 10 polynomial. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f79113",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "-----\n",
    "### Congratulations, we're done!\n",
    "Written by Dr. Liz Munch, Michigan State University\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribution-NonCommercial 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8354f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "3e3338d56a43a0108f5ff8ffc1915439f9812d920a0d5bf5d66e4a60c981234a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
