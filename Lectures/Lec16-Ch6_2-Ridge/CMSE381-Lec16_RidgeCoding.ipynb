{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dfd68f5",
   "metadata": {},
   "source": [
    "# Lec 16 Lab: Ridge Regression\n",
    "## CMSE 381 - Fall 2022\n",
    "## Oct 17, 2022\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90aa0b0",
   "metadata": {},
   "source": [
    "In this module we are going to test out the ridge regression method we discussed in class from Chapter 6.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea3a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everyone's favorite standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "\n",
    "# ML imports we've used previously\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f9a257",
   "metadata": {},
   "source": [
    "# Loading in the data\n",
    "\n",
    "Ok, here we go, let's play with a baseball data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a59a159",
   "metadata": {},
   "outputs": [],
   "source": [
    "hitters_df = pd.read_csv('Hitters.csv')\n",
    "hitters_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3549cda",
   "metadata": {},
   "source": [
    "Annoyingly enough we have some missing values in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9032bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of null values:\", hitters_df[\"Salary\"].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a40baef",
   "metadata": {},
   "source": [
    "So let's go clean those up....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2f6b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the dimensions of the original Hitters data (322 rows x 20 columns)\n",
    "print(\"Dimensions of original data:\", hitters_df.shape)\n",
    "\n",
    "# Drop any rows the contain missing values, along with the player names\n",
    "hitters_df = hitters_df.dropna().drop('Player', axis=1)\n",
    "\n",
    "# Print the dimensions of the modified Hitters data (263 rows x 20 columns)\n",
    "print(\"Dimensions of modified data:\", hitters_df.shape)\n",
    "\n",
    "# One last check: should return 0\n",
    "print(\"Number of null values:\", hitters_df[\"Salary\"].isnull().sum())\n",
    "\n",
    "hitters_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a060d0",
   "metadata": {},
   "source": [
    "And finally, we can replace our categorical variables with dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79df01ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "hitters_df = pd.get_dummies(hitters_df, drop_first = True)\n",
    "hitters_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4672d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = hitters_df.Salary\n",
    "\n",
    "# Drop the column with the independent variable (Salary)\n",
    "X = hitters_df.drop(['Salary'], axis = 1).astype('float64')\n",
    "\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f83fd5",
   "metadata": {},
   "source": [
    "# Ridge Regression\n",
    "\n",
    "In class, we learned that doing ridge regression means that we try to find the best model accoding to the score\n",
    "$$\n",
    "RSS + \\lambda \\sum_{i} \\beta_i^2.\n",
    "$$\n",
    "The good news is that `scikitlearn` has a built in `Ridge` function.  \n",
    "\n",
    "- [Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)\n",
    "- [User guide](https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707a7810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21cc7f7",
   "metadata": {},
   "source": [
    "The bad (ok, not honestly that bad) news is that they call their $\\lambda$ parameter $\\alpha$. So we're just going to minimize \n",
    "$$\n",
    "RSS + \\alpha \\sum_{i} \\beta_i^2.\n",
    "$$\n",
    "instead. So if I pick an alpha value, I can do ridge regression as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e548cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(normalize = True) \n",
    "\n",
    "a = 1 #<------ this is me picking an alpha value\n",
    "\n",
    "ridge.set_params(alpha = a)\n",
    "ridge.fit(X, y)\n",
    "\n",
    "print('intercept:', ridge.intercept_)\n",
    "print('\\n')\n",
    "print(pd.Series(ridge.coef_, index = X.columns))\n",
    "print('\\nTraining MSE:',mean_squared_error(y,ridge.predict(X)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640ca6c9",
   "metadata": {},
   "source": [
    "\n",
    "&#9989; **<font color=red>Q:</font>** What is the `normalize=True` bit doing in the code above?\n",
    "\n",
    "* Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d25cce",
   "metadata": {},
   "source": [
    "Of course, that was just me picking a random $\\alpha$ out of a hat so there's no reason to trust that it's a good one. I could sit here all day and move that $\\alpha$ around to see what's going on, but why do that, when I can make a for loop!\n",
    "\n",
    "Here's a pile of $\\alpha$s for us to test on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a875cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(4,-2,100)*0.5\n",
    "alphas = np.append(alphas,0)\n",
    "alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac7d033",
   "metadata": {},
   "source": [
    "First off, let's take a look at how the coefficients learned change for various choices of $\\alpha$. \n",
    "\n",
    "Associated with each alpha value is a vector of ridge regression coefficients, which we'll store in a matrix coefs. In this case, it is a  19×100  matrix, with 19 rows (one for each predictor) and 100 columns (one for each value of alpha). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6e982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(normalize = True)\n",
    "coefs = []\n",
    "\n",
    "for a in alphas:\n",
    "    ridge.set_params(alpha = a)\n",
    "    ridge.fit(X, y)\n",
    "    coefs.append(ridge.coef_)\n",
    "    \n",
    "np.shape(coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d904830d",
   "metadata": {},
   "source": [
    "First off, let's take a look at how the coefficients learned change for various choices of $\\alpha$. \n",
    "\n",
    "Associated with each alpha value is a vector of ridge regression coefficients, which we'll store in a matrix coefs. In this case, it is a  19×100  matrix, with 19 rows (one for each predictor) and 100 columns (one for each value of alpha). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3610ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0100e9",
   "metadata": {},
   "source": [
    "\n",
    "&#9989; **<font color=red>Q:</font>** There are two variables that have higher magnitude than the rest for low $\\alpha$s (read: are either very large positive or very large negative). Which two are they from the data set? Which is which?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23ad591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3012f155",
   "metadata": {},
   "source": [
    "Now we can start setting up the usual train/test splits to have at least a starting idea of how the testing error is going. The `random_state=1` bit just makes it so that everyone should get the same random split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d835cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee551fba",
   "metadata": {},
   "source": [
    "\n",
    "&#9989; **<font color=red>Do this:</font>** Train a model using ridge regression with $\\alpha = 4$. What is the MSE of your model on the testing set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f70c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51f78b6",
   "metadata": {},
   "source": [
    "\n",
    "&#9989; **<font color=red>Do this:</font>** Ha ha nah, you can do better than that.  Lets try all our alphas and take a look at the testing MSE to make a better decision about what $\\alpha$ we might want. Modify the code below to plot your testing MSE for all the alphas. What $\\alpha$ should we use to train the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2d6e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify your code from above and add it in the for loop to plot the testing MSE\n",
    "\n",
    "ridge = Ridge(normalize = True)\n",
    "errors = []\n",
    "\n",
    "for a in alphas:\n",
    "    # ==== Your code goes in here ==== #\n",
    "    errors.append(17) #<----- random number in here so that the code runs before you fix it\n",
    "    \n",
    "np.shape(errors)\n",
    "\n",
    "plt.plot(alphas,errors)\n",
    "plt.title('Testing MSE')\n",
    "ax=plt.gca()\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692e0478",
   "metadata": {},
   "source": [
    "## RidgeCV\n",
    "\n",
    "Whelp, your meanie professor didn't tell you that there's actually a built in function to do this for you (sorry-not-sorry). Aren't you glad you didn't read ahead?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545f8331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d1510b",
   "metadata": {},
   "source": [
    "- [Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html)\n",
    "- [User Guide](https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression)\n",
    "\n",
    "Basically, `RidgeCV` runs LOOCV (unless you tell it otherwise, see the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html)) on all the alpha values you specify on an input array, and tells you the best $\\alpha$ given that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b437b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to drop that 0 from the alphas because it makes \n",
    "# RidgeCV cranky\n",
    "alphas = alphas[:-1]\n",
    "\n",
    "\n",
    "ridgecv = RidgeCV(alphas = alphas, \n",
    "                  scoring = 'neg_mean_squared_error', \n",
    "                  normalize = True)\n",
    "ridgecv.fit(X_train, y_train)\n",
    "print('alpha chosen is', ridgecv.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7759291",
   "metadata": {},
   "source": [
    "I can predict my values on the test set directly from the `ridgecv` model we just built. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8577eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ridgecv.predict(X_test)\n",
    "mean_squared_error(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe0dfc5",
   "metadata": {},
   "source": [
    "This is exactly the same result as if I went and retrained my model using the chosen $\\alpha$ using `Ridge`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ad65f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha = ridgecv.alpha_, normalize = True)\n",
    "ridge.fit(X_train, y_train)\n",
    "mean_squared_error(y_test, ridge.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d5384c",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** Why did we get a different best choice of $\\alpha$ than we found in the previous section? \n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f79113",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "-----\n",
    "### Congratulations, we're done!\n",
    "Written by Dr. Liz Munch, Michigan State University\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribution-NonCommercial 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8354f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
