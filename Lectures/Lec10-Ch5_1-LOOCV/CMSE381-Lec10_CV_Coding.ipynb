{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dfd68f5",
   "metadata": {},
   "source": [
    "# Lab: Validation set and Cross-Validation\n",
    "## CMSE 381 - Fall 2022\n",
    "## Oct 3,  2022. Lecture 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea3a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everyone's favorite standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d0c63f",
   "metadata": {},
   "source": [
    "# 1. Validation set\n",
    "\n",
    "\n",
    "\n",
    "The first thing we will do is try out the validation set approach. Dispite what our homework assignments would lead you to believe, we have some fabulous functions available in scikit learn that mean we really don't need to do all this work ourselves.\n",
    "\n",
    "\n",
    "## Validation set on toy data\n",
    "\n",
    "First off, let's generate some toy data just to mess around. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e321f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed so everyone has the same numbers\n",
    "np.random.seed(42)\n",
    "\n",
    "def f(t, m = -3, b = 2):\n",
    "    return m*t+b\n",
    "\n",
    "n = 300\n",
    "X_toy = np.random.uniform(0,5,n)\n",
    "y_toy = f(X_toy) + np.random.normal(0,2,n)\n",
    "\n",
    "plt.scatter(X_toy,y_toy)\n",
    "plt.plot(X_toy,f(X_toy),c = 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf3fe63",
   "metadata": {},
   "source": [
    "Ok, so now we have our fake data set up.  Extracting training and testing sets is as simple as the following single line.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f157ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "randomseed = 48824\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_toy,y_toy, test_size=0.2, random_state=randomseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d094a6aa",
   "metadata": {},
   "source": [
    "What this does is extracts two pairs of input/output variables $X$ and $y$.  The train we will use to train our models, and then we will test (or validate) them on the test data. \n",
    "\n",
    "One way to see what these sets are is to plot them, although usually we have much higher $p$ (a.k.a. way more input variables) so we can't really visualize like this normally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f269e617",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train,y_train, marker = '+', label = \"Training\")\n",
    "plt.scatter(X_test,y_test, marker = '*', label = \"Testing\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df821b9",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** Set up a linear regression model, train it on the training set, and test it on the test set.  What is your mean squared error? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9500f236",
   "metadata": {},
   "source": [
    "Now that we can see what happens in one case, let's try doing this many times.  The code below generates a new train/test split. What happens to the MSE? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa6ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the random seed to get a new split of the data\n",
    "randomseed +=1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_toy,y_toy, test_size=0.2, random_state=randomseed)\n",
    "plt.scatter(X_train,y_train, marker = '+', label = \"Training\")\n",
    "plt.scatter(X_test,y_test, marker = '*', label = \"Testing\")\n",
    "plt.legend()\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train.reshape(-1,1),y_train)\n",
    "y_hat = model.predict(X_test.reshape(-1,1))\n",
    "\n",
    "mean_squared_error(y_hat,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09ba2a6",
   "metadata": {},
   "source": [
    "\n",
    "&#9989; **<font color=red>Do this:</font>**  Run the abve script in a loop, repeating $k=30$ times. Keep track of the MSE in a list and draw a histogram of the results. What do you notice? If you want to see more pattern, set $k$ to be something larger like 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d17f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430024cc",
   "metadata": {},
   "source": [
    "\n",
    "![Stop Icon](https://upload.wikimedia.org/wikipedia/commons/thumb/1/1e/Vienna_Convention_road_sign_B2a.svg/180px-Vienna_Convention_road_sign_B2a.svg.png)\n",
    "\n",
    "Great, you got to here! Hang out for a bit, there's more lecture before we go on to the next portion. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006fbd25",
   "metadata": {},
   "source": [
    "# 2. Leave One Out Cross Validation (LOOCV)\n",
    "\n",
    "Luckily, `sklearn` has a simple built in procedure to extract your LOOCV splits for easily passing to your models. However, these work a bit differently than before. As always, the `sklearn` documentation and user guide is an excellent place to start. \n",
    "\n",
    "- [LOOCV Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html)\n",
    "- [LOOCV User guide](https://scikit-learn.org/stable/modules/cross_validation.html#leave-one-out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa8b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm copying the same code from above just so we're restarting with the same data. \n",
    "\n",
    "\n",
    "# Set the seed so everyone has the same numbers\n",
    "np.random.seed(42)\n",
    "\n",
    "def f(t, m = -3, b = 2):\n",
    "    return m*t+b\n",
    "\n",
    "n = 300\n",
    "X_toy = np.random.uniform(0,5,n)\n",
    "y_toy = f(X_toy) + np.random.normal(0,2,n)\n",
    "\n",
    "plt.scatter(X_toy,y_toy)\n",
    "plt.plot(X_toy,f(X_toy),c = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff0e6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(X_toy)\n",
    "\n",
    "# Notice that trying to print loo doesn't give us much that's useful\n",
    "print(loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e58c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The power of the function shows up when we use it in a for loop:\n",
    "for train_index, test_index in loo.split(X_toy):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ffcf23",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Question:</font>** What's the difference between the `LOO.split` output and the `train_test_split` from before?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cd4cc3",
   "metadata": {},
   "source": [
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d51a581",
   "metadata": {},
   "source": [
    "The code below fixes the problem, and draws a figure like above where we get to see which data point is part of the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddca37ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These generator objects are a bit weird, so I can't just pull one split\n",
    "# out of the list. The code below is a bit convoluted, but essentially I'm \n",
    "# just trying to draw the last train/test split found. \n",
    "countPrint = 0\n",
    "maxPrint = 5 # If you change this number, a different point will be labeled as \n",
    "             # the testing point.\n",
    "\n",
    "for train_index, test_index in loo.split(X_toy):\n",
    "\n",
    "    countPrint +=1 \n",
    "\n",
    "    X_train, X_test = X_toy[train_index], X_toy[test_index]\n",
    "    y_train, y_test = y_toy[train_index], y_toy[test_index]\n",
    "    \n",
    "    # Uncomment if you want to see how this fixes it\n",
    "#     print(X_train,y_train)\n",
    "#     print(X_test, y_test)\n",
    "#     print('\\n')\n",
    "\n",
    "    if countPrint >= maxPrint:\n",
    "        break\n",
    "\n",
    "plt.scatter(X_train,y_train, marker = '+', label = \"Training\")\n",
    "plt.scatter(X_test,y_test, marker = '*', label = \"Testing\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446eb709",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** Use the leave one out splits to perform a linear regression on each one, return the mean squared error, and then average over all the values to get the LOOCV error estimation.\n",
    "\n",
    "What do you notice about this error estimation vs. the validation set version above? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b5524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f79113",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "-----\n",
    "### Congratulations, we're done!\n",
    "Written by Dr. Liz Munch, Michigan State University\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribution-NonCommercial 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8354f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "3e3338d56a43a0108f5ff8ffc1915439f9812d920a0d5bf5d66e4a60c981234a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
