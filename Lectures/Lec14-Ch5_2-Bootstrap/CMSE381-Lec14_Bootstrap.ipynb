{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dfd68f5",
   "metadata": {},
   "source": [
    "# Lec 14: Boostrap Coding Portion\n",
    "## CMSE 381 - Fall 2022\n",
    "## Oct 12, 2022\n",
    "\n",
    "In this lab, we are going to follow along with the book to generate boostrap samples. \n",
    "\n",
    "While `sklearn` does have a method called [`Bootstrap`](https://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/modules/generated/sklearn.cross_validation.Bootstrap.html), it doesn't quite do what we want in terms of the example from class.  So instead, we're going to use even simpler functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90aa0b0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea3a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everyone's favorite standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3270f8bf",
   "metadata": {},
   "source": [
    "# 0. Generating data sets \n",
    "\n",
    "Below is some code that generates the data sets as described in Ch 5.2. Specifically, we wish to invest a fixed sum of money in two financial assets that yield returns of $X$ and $Y$, respectively, where $X$ and $Y$ are random quantities. \n",
    "\n",
    "We will invest a fraction $\\alpha$ of our money in $X$, and will invest the remaining $(1-\\alpha)$ in $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0029345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that every time you rerun this function, you will get a new random sample.\n",
    "def generatePortfolio(varX = 1, varY = 1.25,varXY = 0.5, seed = None):\n",
    "    cov = np.array(((varX, varXY), (varXY, varY)))\n",
    "\n",
    "    mean = (0,0)\n",
    "    \n",
    "    # This sets the seed if we don't want to generate a new data set each time\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # This generates our random data\n",
    "    portfolio = np.random.multivariate_normal(mean, cov, (100))\n",
    "    \n",
    "    portfolio = pd.DataFrame(portfolio, columns = ['X', 'Y'])\n",
    "    return portfolio\n",
    "\n",
    "portfolio = generatePortfolio(seed = 42)\n",
    "portfolio.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b6457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(portfolio.X, portfolio.Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef5e7d8",
   "metadata": {},
   "source": [
    "If I want to see how much money I'd make in each case based on a fixed alpha, I can color the points by the amount of income I would get if that pair of $X$ $Y$ values occured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c96986",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.2 #<----- Messing with this number, changes what percentage I invest\n",
    "            #       in each company. \n",
    "\n",
    "income = portfolio.X*alpha + (1-alpha)*portfolio.Y\n",
    "\n",
    "plt.scatter(portfolio.X, portfolio.Y, c = income)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ecb6b3",
   "metadata": {},
   "source": [
    "**<font color=red>Warning:</font>**  I'm following the book in that they call the second column $Y$, but we're not doing a variable prediction with this data set. We just happen to have  labeled the outputs of our two companies $X$ and $Y$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5dad87",
   "metadata": {},
   "source": [
    "# 1. Approximate $\\hat \\alpha$ with simulated data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec127ab7",
   "metadata": {},
   "source": [
    "We're assuming we're investing $\\alpha$ percent of our money in stock $X$ and $(1-\\alpha)$ percent of our money in stock $Y$. Our goal is to minimize the variance \n",
    "$$ \\mathrm{Var}(\\alpha X + (1-\\alpha)Y)$$\n",
    "\n",
    "In your homework, you will show that the variance is minimized when \n",
    "$$\n",
    "\\alpha = \\frac{\\sigma_Y^2 - \\sigma_{XY}}{\\sigma_X^2 + \\sigma_Y^2 - 2\\sigma_{XY}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fc6cf1",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** First, based on the parameters we used to simulate our data, determine the true value of $\\alpha$. *(Hint: You know what the answer should be from the slides, so make sure you can calculate it based on our inputs)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65c2d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dfc139",
   "metadata": {},
   "source": [
    "Next, we will figure out how to approximate $\\alpha$ using the computed covariance from our particular data set. We can find the values for variance and covariance for our simulated data in pandas' covariance matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd50337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf13d63",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** Edit the function `alpha_hat` below which takes in a data frame and returns the predicted $\\hat \\alpha$ using the equation above. Use your function on the entire data set to get an estimate $\\hat \\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa5262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_hat(df):\n",
    "    # Your code here #\n",
    "    pass \n",
    "\n",
    "    return 0 #<---- clearly this shouldn't always return 0\n",
    "    \n",
    "\n",
    "alpha_hat(portfolio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631ef6f8",
   "metadata": {},
   "source": [
    "Now, if your `alpha_hat` code is working, the following loop will generate 1000 data sets, calculate $\\hat \\alpha$ for each, and draw a histogram of the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea69f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "allAlphas = [] \n",
    "for i in range (1000):\n",
    "    \n",
    "    # Resimualte a new portfolio data set. Because I'm not passing \n",
    "    # in a seed, I get a new portfolio data set every time. \n",
    "    portfolio = generatePortfolio()\n",
    "    \n",
    "    # Compute the alpha_hat and append it to my list\n",
    "    allAlphas.append(alpha_hat(portfolio))\n",
    "    \n",
    "print('Mean:', round(np.mean(allAlphas),2))\n",
    "print('StDev:', round(np.std(allAlphas),2))\n",
    "\n",
    "    \n",
    "plt.hist(allAlphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e932b0f2",
   "metadata": {},
   "source": [
    "\n",
    "![Stop Icon](https://upload.wikimedia.org/wikipedia/commons/thumb/1/1e/Vienna_Convention_road_sign_B2a.svg/180px-Vienna_Convention_road_sign_B2a.svg.png)\n",
    "\n",
    "Great, you got to here! Hang out for a bit, there's more lecture before we go on to the next portion. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009bd887",
   "metadata": {},
   "source": [
    "# 2. Resampling data \n",
    "\n",
    "Ok, so normally we don't have access to those original parameters to figure out what $\\alpha$ actually should be, nor do we have the ability to simulate data for ourselves. So, the answer is the boostrap!\n",
    "\n",
    "First, we get our data set. **<font color=red>Note</font>**: For the rest of this exercise, I pretend that I am not allowed to simulate anything. I was just handed this data set and it's all I get to work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d14c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = generatePortfolio(seed = 0)\n",
    "plt.scatter(portfolio.X, portfolio.Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8d711d",
   "metadata": {},
   "source": [
    "The main thing we need to do is to sample our data set with replacement, which we can do with the `sample` function built into the data frame. In this function, `frac=1` means that we use 100% of our data (so we end up with $n$ samples from our original $n$ data points), and `replace=True` means we get to pick points with replacement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bf7b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_port = portfolio.sample(frac=1,replace=True)\n",
    "\n",
    "print('Notice that the `samp_port` dataframe has 100 rows.')\n",
    "print('Length of samp_port:', len(samp_port.index))\n",
    "\n",
    "print('\\nbut if we get rid of duplicates we have less \\nthan 100 data points represented.')\n",
    "print('Length of samp_port without duplicates:', len(set(samp_port.index)))\n",
    "samp_port.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359f2903",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** Repeat the following procedure 1000 times:\n",
    "- Generate a new sample of your `portfolio` data set (Note: DO NOT resimulate your portfolio data set)\n",
    "- Use your `alpha_hat` function from above to compute $\\hat \\alpha$ and keep it in your list\n",
    "\n",
    "Then, draw a histogram of the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1418918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphahats = []\n",
    "B = 1000 #<---- maybe set this to 10 or so while you're debugging\n",
    "\n",
    "for i in range(B):\n",
    "    \n",
    "    # Put your code in here\n",
    "    pass\n",
    "\n",
    "# a printout for debugging\n",
    "print(alphahats[:10])\n",
    "\n",
    "plt.hist(alphahats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a2d3ec",
   "metadata": {},
   "source": [
    "The last thing to do is determine the error estimate. Eqn 5.8 in the book says that we can estimate the error using \n",
    "$$\n",
    "SE_B(\\hat \\alpha) = \\sqrt{ \\frac{1}{B-1}\n",
    "\t\\sum_{r=1}^B \\left(\n",
    "\t\\hat \\alpha^{*r} - \\frac{1}{B}\\sum_{r'=1}^B \\hat \\alpha^{*r'}\n",
    "\t\\right)^2\n",
    "\t}\n",
    "    $$\n",
    "where $\\hat \\alpha^{*i}$ is the $i$th prediction (AKA the $i$th entry in your `alphahats` list up there). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b550471",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** Use your `alphahats` list  to determine the standard error of $\\hat \\alpha$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74e9a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f79113",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "-----\n",
    "### Congratulations, we're done!\n",
    "Written by Dr. Liz Munch, Michigan State University\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribution-NonCommercial 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8354f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
